{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/a03102030/plant-pathology-2020-resnet50\n",
    "#384\n",
    "# 資料處理套件\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg # mpimg 用於讀取圖片\n",
    "import matplotlib.pyplot as plt # plt 用於顯示圖片\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定顯示中文字體\n",
    "from matplotlib.font_manager import FontProperties\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras深度學習模組套件\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras import utils as np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow深度學習模組套件\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#遷移式學習import\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "#B7\n",
    "import efficientnet.tfkeras as efn\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#print(pd.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料集標籤檔\n",
    "Sample_label = pd.read_csv(\"C:/Users/danie/AOI_test/train01.csv\",encoding=\"utf8\")\n",
    "# 顯示資料集標籤檔\n",
    "Sample_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 串接圖片檔的路徑\n",
    "Sample_pics_path = os.path.join(\"C:/Users/danie/AOI_test/train_images\")\n",
    "# 讀取路徑中的圖片\n",
    "train_mango_fnames = os.listdir(Sample_pics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#測試圖片\n",
    "print(train_mango_fnames[0])\n",
    "print(train_mango_fnames[1])\n",
    "print(train_mango_fnames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取圖檔\n",
    "img = mpimg.imread(\"C:/Users/danie/AOI_test/train_images/train_00001.png\")\n",
    "# 查看資料型態\n",
    "print(type(img))\n",
    "# 顯示圖片的比例\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把圖片的比例壓縮至800x800 \n",
    "res = cv2.resize(img,(800,800),interpolation=cv2.INTER_LINEAR)\n",
    "# 顯示壓縮後圖片的比例\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示原圖的芒果照片\n",
    "plt.imshow(img)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 顯示壓縮過原圖的芒果照片\n",
    "plt.imshow(res)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作標籤&資料集\n",
    "csvfile = open('C:/Users/danie/AOI_test/train01.csv')\n",
    "reader = csv.reader(csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取csv標籤\n",
    "labels = []\n",
    "for line in reader:\n",
    "    tmp = [line[0],line[1]]\n",
    "    # print tmp\n",
    "    labels.append(tmp)\n",
    "\n",
    "csvfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picnum = len(labels)\n",
    "print(\"AOI圖片數量:\",picnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換圖片的標籤\n",
    "for i in range(len(labels)):\n",
    "    labels[i][1] = labels[i][1].replace(\"0\",\"0\")\n",
    "    labels[i][1] = labels[i][1].replace(\"1\",\"1\")\n",
    "    labels[i][1] = labels[i][1].replace(\"2\",\"2\")\n",
    "#測試是否有傳換成功\n",
    "print(labels[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 隨機讀取圖片\n",
    "# a = 0\n",
    "# items= []\n",
    "# import random\n",
    "# for a in range(0,45000):\n",
    "#     items.append(a)\n",
    "    \n",
    "a = 0\n",
    "items= []\n",
    "for a in range(0,2528):\n",
    "    items.append(a)\n",
    "print(items[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 製作訓練用資料集及標籤\n",
    "# for i in random.sample(items,45000):\n",
    "#     img = cv2.imread(\"C:/Users/danie/mango/C1-P2_Train Dev/Crop_Train/\" + labels[i][0] )\n",
    "#     res = cv2.resize(img,(224,224),interpolation=cv2.INTER_LINEAR)\n",
    "#     res = img_to_array(res)\n",
    "#     X.append(res)    \n",
    "#     y.append(labels[i][1])\n",
    "# print(\"done\")\n",
    "\n",
    "# 製作訓練用資料集及標籤\n",
    "for i in items:\n",
    "    img = cv2.imread(\"C:/Users/danie/AOI_test/train_images/\" + labels[i][0])\n",
    "    res = cv2.resize(img,(512,512),interpolation=cv2.INTER_LINEAR)\n",
    "    res = img_to_array(res)\n",
    "    X.append(res)\n",
    "    y.append(labels[i][1])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_org = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換至array的格式\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換至float的格式\n",
    "for i in range(len(X)):\n",
    "    X[i] = X[i].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打映圖片訓練集的概況\n",
    "# print(X[0])\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "print(X[0].shape)\n",
    "print(type(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將標籤轉換至float格式\n",
    "#y = tf.strings.to_number(y, out_type=tf.float32)\n",
    "for i in range(len(y)):\n",
    "    y[i] = y[i].astype('float32')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打映圖片標籤的概況\n",
    "print(y[0])\n",
    "print(type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標籤進行one-hotencoding\n",
    "y = np_utils.to_categorical(y, num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[:1770]\n",
    "y_train = y[:1770]\n",
    "x_val = X[1770:]\n",
    "y_val = y[1770:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = [0.,0.,0.,0.,0.,0.]\n",
    "\n",
    "for i in range(0,len(y_train)):\n",
    "    y_train_label = y_train[i] + y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_train))\n",
    "print(len(x_train))\n",
    "print(x_train.shape)\n",
    "print(type(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use the VGG19 model \n",
    "# image_input = Input(shape=(224, 224, 3))\n",
    "# ###  CODE HERE ###  (≈ 1 lines)\n",
    "# vgg_model = VGG19(input_tensor=image_input, include_top=True, weights='imagenet')\n",
    "# vgg_model.summary()\n",
    "\n",
    "#EB7 model\n",
    "model_finetuned = tf.keras.Sequential([efn.EfficientNetB0(input_shape=(512, 512, 3),\n",
    "                                                weights='imagenet',\n",
    "                                                #weights='noisy-student',\n",
    "                                                include_top=False),\n",
    "                                       L.GlobalAveragePooling2D(),\n",
    "                                       L.Dense(6,activation='softmax')])\n",
    "model_finetuned.compile(optimizer='adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model_finetuned.summary()\n",
    "\n",
    "# model_finetuned = ResNet50(include_top=False, weights='imagenet', input_shape=(384,384,3))\n",
    "# x = model_finetuned.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(128, activation=\"relu\")(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "# predictions = Dense(3, activation=\"softmax\")(x)\n",
    "# model_finetuned = Model(inputs=model_finetuned.input, outputs=predictions)\n",
    "# model_finetuned.compile(optimizer='adam',\n",
    "#                   loss = 'categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "# model_finetuned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam = optimizers.adam(lr=5)\n",
    "#model.compile(optimizer='adam',\n",
    "#              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#              metrics=['acc'])\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zca_whitening 對輸入數據施加ZCA白化\n",
    "# rotation_range 數據提升時圖片隨機轉動的角度\n",
    "# width_shift_range 圖片寬度的某個比例，數據提升時圖片水平偏移的幅度\n",
    "# shear_range 剪切強度（逆時針方向的剪切變換角度）\n",
    "# zoom_range 隨機縮放的幅度\n",
    "# horizontal_flip 進行隨機水平翻轉\n",
    "# fill_mode ‘constant’，‘nearest’，‘reflect’或‘wrap’之一，當進行變換時超出邊界的點將根據本參數給定的方法進行處理\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1,\n",
    "    rescale=1/255,\n",
    "    brightness_range=[0.5, 1.5])\n",
    "\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     zca_whitening=False,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest',\n",
    "#     rescale=1/255, #多加的\n",
    "#     brightness_range=[0.5, 1.5]\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入圖像增強參數\n",
    "datagen.fit(x_train)\n",
    "x_train = x_train/255\n",
    "x_val = x_val/255\n",
    "print('rescale！done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定超參數HyperParameters \n",
    "batch_size =  8\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(epochs)+'_'+str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 學習速率調整\n",
    "# LR_START = 0.00001\n",
    "# LR_MAX = 0.0001 * 8\n",
    "# LR_MIN = 0.00001\n",
    "# LR_RAMPUP_EPOCHS = 10\n",
    "# LR_SUSTAIN_EPOCHS = 2\n",
    "# LR_EXP_DECAY = .8\n",
    "\n",
    "# def lrfn(epoch):\n",
    "#     if epoch < LR_RAMPUP_EPOCHS:\n",
    "#         lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "#     elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "#         lr = LR_MAX\n",
    "#     else:\n",
    "#         lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "#     return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入EarlyStopping以及Tensorboard等回調函數\n",
    "# CB = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# TB = keras.callbacks.TensorBoard(log_dir='./log'+\"_\"+file_name, histogram_freq=1)\n",
    "\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=10, min_lr=0.001)\n",
    "# EB7\n",
    "# lrfn = build_lrfn()\n",
    "#STEPS_PER_EPOCH = y_train.shape[0] // batch_size\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "# reduce_lr =  ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 10,\n",
    "#   verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,\n",
    "#   min_lr = 1e-5)\n",
    "# es = EarlyStopping(monitor = \"val_loss\" , verbose = 1 , mode = 'min' , patience = 50 )\n",
    "# mc = ModelCheckpoint('best_model.h5', monitor = 'loss' , mode = 'min', verbose = 1 , save_best_only = True)\n",
    "\n",
    "#lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "# 小更動使用\n",
    "#bestckpt_filepath = 'C:/Users/danie/mango/C1-P2_Train Dev/modelsave_ckpt/New_Mangotest_crop_and_B5_3/efnetB5forMango.best.hdf5'\n",
    "allckpt_filepath=\"C:/Users/danie/AOI_test/Model_H5/AOI_efficientB0_fortest_P1/weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "RLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.3,patience=2, min_lr = 1e-5)\n",
    "ckptforall = ModelCheckpoint(allckpt_filepath, monitor='categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#ckptforbest = ModelCheckpoint(bestckpt_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_finetuned.fit(\n",
    "    x = x_train , y = y_train,                                    \n",
    "    #steps_per_epoch=100,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    #validation_steps=100,\n",
    "    verbose=1,\n",
    "    callbacks=[RLR, ckptforall],\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推測圖片\n",
    "test_mango_dir = os.path.join(\"C:/Users/danie/AOI_test/train_images/\")\n",
    "test_mango_fnames = os.listdir(test_mango_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = [os.path.join(test_mango_dir,f) for f in test_mango_fnames]\n",
    "img_path = random.choice(img_files)\n",
    "\n",
    "# 讀入待測試圖像並秀出\n",
    "img = load_img(img_path, target_size=(512, 512))  # this is a PIL image\n",
    "plt.title(img_path)\n",
    "plt.grid(False)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0','1',\"2\",'3','4','5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將圖像轉成模型可分析格式(800x800x3, float32)\n",
    "x = img_to_array(img)  # Numpy array with shape (800, 800, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 800, 800, 3)\n",
    "x /= 255 # Rescale by 1/255\n",
    "\n",
    "start = time.time() # 啟動計時器\n",
    "result = model_finetuned.predict(x) # 對輸入圖像進行推論(預測)\n",
    "finish = time.time() # 結束計時器\n",
    "\n",
    "pred = result.argmax(axis=1)[0]\n",
    "pred_prob = result[0][pred]\n",
    "\n",
    "print(\"Result = %f\" %pred_prob) # 印出結果可能機率值(0.0 ~ 1.0)\n",
    "print(\"Test time :%f second.\" %(finish-start)) # 印出推論時間\n",
    "\n",
    "# 設定分類門檻值並印出推論結果\n",
    "print(\"有 {:.2f}% 機率為{}\".format(pred_prob * 100,labels[pred])) # 印出推論時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試集標籤預測\n",
    "y_pred = model_finetuned.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整體準確度\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if(np.argmax(y_pred[i]) == np.argmax(y_val[i])): #argmax函数找到最大值的索引，即为其类别\n",
    "        count += 1\n",
    "score = count/len(y_pred)\n",
    "print('正确率为:%.2f%s' % (score*100,'%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型預測後的標籤\n",
    "predict_label = np.argmax(y_pred,axis=1)\n",
    "print(predict_label)\n",
    "print(len(predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型原標籤\n",
    "true_label = y_label_org[1770:]\n",
    "true_label = np.array(true_label)\n",
    "print(true_label)\n",
    "print(len(true_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型預測後的標籤\n",
    "# predictions = model.predict_classes(x_test)\n",
    "# print(predictions)\n",
    "# print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(true_label,predict_label,rownames=['實際值'],colnames=['預測值'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 儲存模型相關參數\n",
    " #model_finetuned.save(\"C:/Users/danie/mango/C1-P2_Train Dev/modelsave_h5/Mango_MDtest2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
